import sys
import time
import logging
import re
import os
from datetime import datetime
from types import FrameType
from typing import cast, Dict
from pathlib import Path
from loguru import logger

from app.core.ctx import CTX_X_REQUEST_ID
from app.settings import APP_SETTINGS

# é…ç½®Tortoise ORMçš„æ—¥å¿—è®°å½•å™¨
tortoise_logger = logging.getLogger("tortoise")
# é»˜è®¤è®¾ç½®ä¸ºWARNINGçº§åˆ«ï¼Œç¦ç”¨SQLæ—¥å¿—
tortoise_logger.setLevel(logging.WARNING)

# æ—¥å¿—é…ç½®æ§åˆ¶æ ‡å¿—
_sql_logging_enabled = False
_current_log_level = "DEBUG"  # é»˜è®¤æ—¥å¿—çº§åˆ«


async def get_logs_directory() -> Path:
    """è·å–æ—¥å¿—ç›®å½•è·¯å¾„ï¼Œä¼˜å…ˆä»æ•°æ®åº“è¯»å–ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤é…ç½®"""
    try:
        # å°è¯•ä»æ•°æ®åº“è¯»å–ç³»ç»Ÿè®¾ç½®
        from app.models.strm import SystemSettings
        settings = await SystemSettings.all().first()

        if settings and settings.logs_directory:
            # å¦‚æœæ•°æ®åº“ä¸­æœ‰é…ç½®ï¼Œä½¿ç”¨æ•°æ®åº“é…ç½®
            logs_dir = Path(settings.logs_directory)

            # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•
            if not logs_dir.is_absolute():
                logs_dir = APP_SETTINGS.BASE_DIR / logs_dir

            # ç¡®ä¿ç›®å½•å­˜åœ¨
            logs_dir.mkdir(parents=True, exist_ok=True)
            return logs_dir.resolve()

    except Exception as e:
        # å¦‚æœè¯»å–æ•°æ®åº“å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
        print(f"è¯»å–æ—¥å¿—ç›®å½•é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")

    # ä½¿ç”¨é»˜è®¤é…ç½® app/logs
    default_logs_dir = APP_SETTINGS.BASE_DIR / "app/logs"
    default_logs_dir.mkdir(parents=True, exist_ok=True)
    return default_logs_dir


async def get_log_retention_days() -> int:
    """è·å–æ—¥å¿—ä¿ç•™å¤©æ•°ï¼Œä¼˜å…ˆä»æ•°æ®åº“è¯»å–ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å€¼"""
    try:
        # å°è¯•ä»æ•°æ®åº“è¯»å–ç³»ç»Ÿè®¾ç½®
        from app.models.strm import SystemSettings
        settings = await SystemSettings.all().first()

        if settings and hasattr(settings, 'log_retention_days') and settings.log_retention_days:
            return settings.log_retention_days

    except Exception as e:
        # å¦‚æœè¯»å–æ•°æ®åº“å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
        print(f"è¯»å–æ—¥å¿—ä¿ç•™å¤©æ•°é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")

    # ä½¿ç”¨é»˜è®¤å€¼ 30å¤©
    return 30


def get_logs_directory_sync() -> Path:
    """åŒæ­¥ç‰ˆæœ¬çš„è·å–æ—¥å¿—ç›®å½•è·¯å¾„"""
    try:
        # å¯¹äºåŒæ­¥è°ƒç”¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½® app/logs
        # è¿™ä¸»è¦ç”¨äºåº”ç”¨å¯åŠ¨æ—¶çš„åˆå§‹åŒ–
        default_logs_dir = APP_SETTINGS.BASE_DIR / "app/logs"
        default_logs_dir.mkdir(parents=True, exist_ok=True)
        return default_logs_dir
    except Exception as e:
        print(f"è·å–æ—¥å¿—ç›®å½•å¤±è´¥: {e}")
        # å¦‚æœé»˜è®¤ç›®å½•ä¹Ÿå¤±è´¥ï¼Œä½¿ç”¨å½“å‰ç›®å½•ä¸‹çš„logs
        fallback_dir = Path("logs")
        fallback_dir.mkdir(parents=True, exist_ok=True)
        return fallback_dir


def get_log_retention_days_sync() -> int:
    """åŒæ­¥ç‰ˆæœ¬çš„è·å–æ—¥å¿—ä¿ç•™å¤©æ•°"""
    try:
        # å¯¹äºåŒæ­¥è°ƒç”¨ï¼Œå°è¯•è¯»å–SQLiteæ•°æ®åº“
        import sqlite3
        db_path = APP_SETTINGS.BASE_DIR / "app_system.sqlite3"

        if db_path.exists():
            conn = sqlite3.connect(str(db_path))
            cursor = conn.cursor()
            cursor.execute("SELECT log_retention_days FROM strm_system_settings LIMIT 1")
            result = cursor.fetchone()
            conn.close()

            if result and result[0] is not None:
                return int(result[0])

    except Exception as e:
        print(f"è¯»å–æ—¥å¿—ä¿ç•™å¤©æ•°é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")

    # ä½¿ç”¨é»˜è®¤å€¼ 30å¤©
    return 30


def set_sql_logging_enabled(enabled: bool):
    """è®¾ç½®SQLæ—¥å¿—æ˜¯å¦å¯ç”¨"""
    global _sql_logging_enabled

    # åªåœ¨çŠ¶æ€çœŸæ­£æ”¹å˜æ—¶æ‰æ‰“å°æ—¥å¿—å’Œè°ƒæ•´è®¾ç½®
    if _sql_logging_enabled != enabled:
        _sql_logging_enabled = enabled

        # åŠ¨æ€è°ƒæ•´Tortoise ORMæ—¥å¿—çº§åˆ«
        if enabled:
            tortoise_logger.setLevel(logging.DEBUG)
            logger.info("ğŸ—„ï¸ SQLæ—¥å¿—å·²å¯ç”¨")
        else:
            tortoise_logger.setLevel(logging.WARNING)
            logger.info("ğŸ—„ï¸ SQLæ—¥å¿—å·²ç¦ç”¨")


def set_log_level(level: str):
    """è®¾ç½®æ—¥å¿—çº§åˆ«"""
    global _current_log_level

    # åªåœ¨çº§åˆ«çœŸæ­£æ”¹å˜æ—¶æ‰æ‰“å°æ—¥å¿—å’Œæ›´æ–°è®¾ç½®
    new_level = level.upper()
    if _current_log_level != new_level:
        _current_log_level = new_level
        logger.info(f"ğŸ“Š æ—¥å¿—çº§åˆ«å·²è®¾ç½®ä¸º: {_current_log_level}")


def get_current_log_level() -> str:
    """è·å–å½“å‰æ—¥å¿—çº§åˆ«"""
    return _current_log_level


def is_sql_logging_enabled() -> bool:
    """æ£€æŸ¥SQLæ—¥å¿—æ˜¯å¦å¯ç”¨"""
    return _sql_logging_enabled


def x_request_id_filter(record):
    record["x_request_id"] = CTX_X_REQUEST_ID.get()
    return record["x_request_id"]


# è¯·æ±‚è®¡æ—¶å™¨ï¼Œç”¨äºå­˜å‚¨æ¯ä¸ªè¯·æ±‚çš„å¼€å§‹æ—¶é—´å’Œå¤„ç†æ—¶é—´
class RequestTimer:
    _instance = None
    _request_times: Dict[str, float] = {}

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(RequestTimer, cls).__new__(cls)
        return cls._instance

    def start_timer(self, request_id):
        """å¼€å§‹è®¡æ—¶"""
        self._request_times[request_id] = time.time()

    def get_elapsed_time(self, request_id):
        """è·å–å¤„ç†æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰"""
        start_time = self._request_times.get(request_id)
        if start_time:
            elapsed = (time.time() - start_time) * 1000
            # æ¸…ç†ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
            del self._request_times[request_id]
            return elapsed
        return None


# å…¨å±€è¯·æ±‚è®¡æ—¶å™¨å®ä¾‹
request_timer = RequestTimer()


class Logger:
    """è¾“å‡ºæ—¥å¿—åˆ°æ–‡ä»¶å’Œæ§åˆ¶å°"""

    def __init__(self):
        self.logger = logger
        self.logger.remove()
        # ä½¿ç”¨åŒæ­¥ç‰ˆæœ¬è·å–æ—¥å¿—ç›®å½•ï¼ˆç”¨äºåˆå§‹åŒ–ï¼‰
        logs_dir = get_logs_directory_sync()
        self._setup_loggers(logs_dir)

    def _setup_loggers(self, logs_dir: Path = None):
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        if logs_dir is None:
            logs_dir = get_logs_directory_sync()

        log_name = f"Fast_{time.strftime('%Y-%m-%d', time.localtime()).replace('-', '_')}.log"
        log_path = logs_dir / log_name

        # è·å–å½“å‰æ—¥å¿—çº§åˆ«
        current_level = get_current_log_level()

        # è®¾ç½®æ§åˆ¶å°è¾“å‡º
        self.logger.add(sys.stdout, level=current_level)

        # è·å–æ—¥å¿—ä¿ç•™å¤©æ•°è®¾ç½®
        retention_days = get_log_retention_days_sync()

        # è®¾ç½®æ–‡ä»¶è¾“å‡ºï¼Œä½¿ç”¨åŠ¨æ€çš„ä¿ç•™å¤©æ•°
        self.logger.add(
            log_path,
            format="{time:YYYY-MM-DD HH:mm:ss} - "
            "{process.name} | "
            "{thread.name} | "
            "<red> {x_request_id} </red> | "
            "{module}.{function}:{line} - {level} -{message}",
            encoding="utf-8",
            retention=f"{retention_days} days",
            backtrace=True,
            diagnose=True,
            enqueue=True,
            rotation="00:00",
            filter=x_request_id_filter,
            level=current_level,
        )

    def reconfigure_loggers(self):
        """é‡æ–°é…ç½®æ—¥å¿—è®°å½•å™¨ï¼ˆå½“è®¾ç½®å‘ç”Ÿå˜åŒ–æ—¶è°ƒç”¨ï¼‰"""
        self.logger.remove()
        # é‡æ–°è·å–æ—¥å¿—ç›®å½•é…ç½®
        logs_dir = get_logs_directory_sync()
        self._setup_loggers(logs_dir)
        logger.info("ğŸ”„ æ—¥å¿—é…ç½®å·²é‡æ–°åŠ è½½")

    async def reconfigure_loggers_async(self):
        """å¼‚æ­¥é‡æ–°é…ç½®æ—¥å¿—è®°å½•å™¨ï¼ˆå½“è®¾ç½®å‘ç”Ÿå˜åŒ–æ—¶è°ƒç”¨ï¼‰"""
        self.logger.remove()
        # å¼‚æ­¥è·å–æ—¥å¿—ç›®å½•é…ç½®
        logs_dir = await get_logs_directory()
        self._setup_loggers(logs_dir)
        logger.info("ğŸ”„ æ—¥å¿—é…ç½®å·²é‡æ–°åŠ è½½")

    @staticmethod
    def init_config():
        LOGGER_NAMES = ("uvicorn.asgi", "uvicorn.access", "uvicorn", "tortoise")

        logging.getLogger().handlers = [InterceptHandler()]
        for logger_name in LOGGER_NAMES:
            logging_logger = logging.getLogger(logger_name)
            logging_logger.handlers = [InterceptHandler()]
            # ä¸ºTortoise ORMé»˜è®¤è®¾ç½®WARNINGçº§åˆ«ï¼Œç¦ç”¨SQLæŸ¥è¯¢æ—¥å¿—
            # SQLæ—¥å¿—çš„å¯ç”¨/ç¦ç”¨é€šè¿‡set_sql_logging_enabledå‡½æ•°æ§åˆ¶
            if logger_name == "tortoise":
                logging_logger.setLevel(logging.WARNING)

    def get_logger(self):
        return self.logger


# å…¨å±€Loggerå®ä¾‹
_global_logger_instance = None


def get_global_logger_instance():
    """è·å–å…¨å±€Loggerå®ä¾‹"""
    global _global_logger_instance
    if _global_logger_instance is None:
        _global_logger_instance = Logger()
    return _global_logger_instance


def reconfigure_global_logger():
    """é‡æ–°é…ç½®å…¨å±€æ—¥å¿—è®°å½•å™¨"""
    global _global_logger_instance
    if _global_logger_instance is not None:
        _global_logger_instance.reconfigure_loggers()


class InterceptHandler(logging.Handler):
    def emit(self, record: logging.LogRecord) -> None:
        try:
            level = logger.level(record.levelname).name
        except ValueError:
            level = str(record.levelno)

        frame, depth = logging.currentframe(), 2
        while frame.f_code.co_filename == logging.__file__:
            frame = cast(FrameType, frame.f_back)
            depth += 1

        message = record.getMessage()

        # å¤„ç†SQLæ—¥å¿—
        if record.name == "tortoise":
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨SQLæ—¥å¿—
            if not _sql_logging_enabled:
                return  # å¦‚æœæœªå¯ç”¨SQLæ—¥å¿—ï¼Œç›´æ¥è¿”å›ä¸å¤„ç†

            # ä¸ºSQLæŸ¥è¯¢æ·»åŠ ç‰¹æ®Šæ ¼å¼
            if "SELECT" in message or "INSERT" in message or "UPDATE" in message or "DELETE" in message:
                message = f"ğŸ—„ï¸ SQL: {message}"
            elif "PRAGMA" in message:
                message = f"ğŸ”§ PRAGMA: {message}"
            else:
                message = f"ğŸ“Š DB: {message}"

        # å¤„ç†è®¿é—®æ—¥å¿—
        elif record.name == "uvicorn.access":
            # åŒ¹é…è®¿é—®æ—¥å¿—æ ¼å¼: 127.0.0.1:34957 - "GET /api/v1/auth/user-info HTTP/1.1" 200
            access_log_pattern = r'([^:]+):(\d+) - "([A-Z]+) ([^ ]+) HTTP/\d\.\d" (\d+)'
            match = re.match(access_log_pattern, message)

            if match:
                client_ip, client_port, method, path, status = match.groups()

                # ä»APILoggerMiddlewareä¸­è·å–å¤„ç†æ—¶é—´
                elapsed_time = getattr(record, "process_time", None)
                if elapsed_time is None:
                    # å°è¯•ä»å½“å‰ä¸Šä¸‹æ–‡è·å–request_id
                    request_id = CTX_X_REQUEST_ID.get()
                    if request_id:
                        elapsed_time = request_timer.get_elapsed_time(request_id)

                # æ·»åŠ å¤„ç†æ—¶é—´åˆ°æ—¥å¿—æ¶ˆæ¯
                if elapsed_time is not None:
                    message = f"{message} - {elapsed_time:.2f}ms"

        logger.opt(depth=depth, exception=record.exc_info).log(level, message)


async def reconfigure_global_logger_async():
    """å¼‚æ­¥é‡æ–°é…ç½®å…¨å±€æ—¥å¿—è®°å½•å™¨"""
    global_logger = get_global_logger_instance()
    if global_logger:
        await global_logger.reconfigure_loggers_async()
        # é‡æ–°é…ç½®åï¼Œæ¸…ç†æ—§çš„æ—¥å¿—æ–‡ä»¶
        await cleanup_old_log_files()


async def cleanup_old_log_files():
    """æ¸…ç†è¶…è¿‡ä¿ç•™æœŸçš„æ—§æ—¥å¿—æ–‡ä»¶"""
    try:
        from datetime import datetime, timedelta
        import os

        # è·å–æ—¥å¿—ç›®å½•å’Œä¿ç•™å¤©æ•°
        logs_dir = await get_logs_directory()
        retention_days = await get_log_retention_days()

        # è®¡ç®—æˆªæ­¢æ—¥æœŸ
        cutoff_date = datetime.now() - timedelta(days=retention_days)

        # æ‰«ææ—¥å¿—ç›®å½•
        if logs_dir.exists():
            log_files_removed = 0
            for log_file in logs_dir.glob("Fast_*.log"):
                try:
                    # ä»æ–‡ä»¶åæå–æ—¥æœŸ (Fast_2025_05_16.log)
                    file_name = log_file.stem  # Fast_2025_05_16
                    date_part = file_name.replace("Fast_", "")  # 2025_05_16
                    file_date = datetime.strptime(date_part, "%Y_%m_%d")

                    # å¦‚æœæ–‡ä»¶æ—¥æœŸæ—©äºæˆªæ­¢æ—¥æœŸï¼Œåˆ é™¤æ–‡ä»¶
                    if file_date < cutoff_date:
                        log_file.unlink()
                        log_files_removed += 1
                        logger.info(f"ğŸ—‘ï¸ å·²åˆ é™¤è¿‡æœŸæ—¥å¿—æ–‡ä»¶: {log_file.name}")

                except (ValueError, OSError) as e:
                    logger.warning(f"âš ï¸ å¤„ç†æ—¥å¿—æ–‡ä»¶ {log_file.name} æ—¶å‡ºé”™: {e}")

            if log_files_removed > 0:
                logger.info(f"ğŸ§¹ æ—¥å¿—æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {log_files_removed} ä¸ªè¿‡æœŸæ–‡ä»¶")
            else:
                logger.info("âœ… æ²¡æœ‰éœ€è¦æ¸…ç†çš„è¿‡æœŸæ—¥å¿—æ–‡ä»¶")

    except Exception as e:
        logger.error(f"âŒ æ¸…ç†æ—§æ—¥å¿—æ–‡ä»¶æ—¶å‡ºé”™: {e}")


Loggers = Logger()
Loggers.init_config()
log = Loggers.get_logger()
